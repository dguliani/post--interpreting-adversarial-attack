@article{carlini2016eval,
  title={Towards Evaluating the Robustness of Neural Networks},
  author={Nicholas Carlini, David Wagner},
  journal={IEEE Symposium on Security and Privacy 2017: 39-57},
  year={2016},
  url={https://arxiv.org/pdf/1608.04644.pdf}
}

@article{gilmer2018motiv,
  title={Motivating the Rules of the Game for Adversarial Example Research},
  author={Filmer, Justin and Adams, Ryan P. and Goodfellow, Ian and Andersen, David and Dahl, George E. },
  year={2018},
  url={https://arxiv.org/pdf/1807.06732.pdf}
}

@article{olah2018blocks,
  author = {Olah, Chris and Satyanarayan, Arvind and Johnston, Ian and Carter, Shan and Schubert, Ludwig and Ye, Katherine and Mordvintsev, Alexander},
  title = {The Building Blocks of Interpretability},
  journal = {Distill},
  year = {2018},
  url = {https://distill.pub/2018/building-blocks/},
  doi = {10.23915/distill.00010}
}

@article{olah2017feature,
  author = {Olah, Chris and Mordvintsev, Alexander and Schubert, Ludwig},
  title = {The Building Blocks of Interpretability},
  journal = {Distill},
  year = {2017},
  url = {https://distill.pub/2017/feature-visualization},
  doi = {10.23915/distill.00007}
}

@article{goodfellow2017attacking, 
  author = {Goodfellow, Ian and Papernot, Nicolas, and Huang, Sandy and Duan, Yan and Abbeel, Pieter and Clark, Jack}, 
  title = {Attacking Machine Learning with Adversarial Examples}, 
  journal = {}, 
  year = {2017}, 
  url = {https://blog.openai.com/adversarial-example-research/}, 
  doi = {}
}